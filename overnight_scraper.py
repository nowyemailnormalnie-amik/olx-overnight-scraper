"""
OVERNIGHT SCRAPER - Znajd≈∫ firmy z >300 og≈Çosze≈Ñ dzia≈ÇajƒÖc przez noc
=====================================================================

Strategia:
1. Iteruj po kategoriach √ó najwiƒôksze miasta Polski
2. Dla ka≈ºdego og≈Çoszenia ‚Üí wyciƒÖgnij user_id
3. Sprawd≈∫ profil u≈ºytkownika (cache ≈ºeby nie powtarzaƒá)
4. Je≈õli >300 og≈Çosze≈Ñ ‚Üí zapisz
5. Checkpoint co 10 u≈ºytkownik√≥w
6. Ranking na bie≈ºƒÖco
"""

import requests
from bs4 import BeautifulSoup
import re
import time
import csv
import json
import random
import os
from datetime import datetime
from collections import defaultdict

class OvernightScraper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
        # Najwiƒôksze miasta w Polsce
        self.cities = [
            'warszawa', 'krakow', 'wroclaw', 'poznan', 'gdansk',
            'szczecin', 'bydgoszcz', 'lublin', 'katowice', 'bialystok'
        ]
        
        # Kategorie (bez motoryzacji!)
        self.categories = [
            'elektronika',
            'moda',
            'dom-ogrod',
            'dla-dzieci',
            'sport-hobby',
            'muzyka-edukacja',
            'zwierzeta',
            'praca',
        ]
        
        # Stan
        self.checked_users = set()  # user_id ju≈º sprawdzonych
        self.found_businesses = {}  # user_id -> {name, ads_count, url}
        
        self.stats = {
            'ads_checked': 0,
            'users_checked': 0,
            'businesses_found': 0,
            'start_time': datetime.now(),
        }
        
    def load_checkpoint(self):
        """Wczytaj poprzedni checkpoint ≈ºeby kontynuowaƒá"""
        print("\nüîÑ Sprawdzam poprzednie wyniki...")
        
        # Wczytaj found_businesses z CSV
        csv_file = "overnight_checkpoint.csv"
        if os.path.exists(csv_file):
            try:
                with open(csv_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        user_id = row['User_ID']
                        self.found_businesses[user_id] = {
                            'name': row['Nazwa'],
                            'ads_count': int(row['Liczba_Ogloszen']),
                            'profile_url': row['URL_Profilu']
                        }
                        self.checked_users.add(user_id)
                
                print(f"   ‚úÖ Wczytano {len(self.found_businesses)} firm z poprzedniego runa")
            except Exception as e:
                print(f"   ‚ö†Ô∏è B≈ÇƒÖd wczytywania CSV: {e}")
        
        # Wczytaj checked_users z cache
        cache_file = "overnight_checkpoint_cache.json"
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    cached_users = set(cache_data.get('checked_users', []))
                    self.checked_users.update(cached_users)
                
                print(f"   ‚úÖ Wczytano {len(cached_users)} ju≈º sprawdzonych u≈ºytkownik√≥w")
                print(f"   ‚ÑπÔ∏è ≈ÅƒÖcznie pomijam {len(self.checked_users)} u≈ºytkownik√≥w\n")
            except Exception as e:
                print(f"   ‚ö†Ô∏è B≈ÇƒÖd wczytywania cache: {e}\n")
        else:
            print(f"   ‚ÑπÔ∏è Brak cache - zaczynam od zera\n")
    
    def extract_user_id_from_url(self, url):
        """WyciƒÖgnij user_id z URL"""
        match = re.search(r'/uzytkownik/([^/]+)', url)
        return match.group(1) if match else None
    
    def get_user_ads_count_fast(self, user_id):
        """Szybkie sprawdzenie liczby og≈Çosze≈Ñ u≈ºytkownika"""
        if user_id in self.checked_users:
            return None  # Ju≈º sprawdzony
        
        self.checked_users.add(user_id)
        
        profile_url = f"https://www.olx.pl/oferty/uzytkownik/{user_id}/"
        
        try:
            # Pojedynczy request na profil
            response = self.session.get(profile_url, timeout=8)
            
            if response.status_code != 200:
                return None
            
            # Szybki regex na liczbie og≈Çosze≈Ñ (bez parsowania ca≈Çego HTML)
            ads_match = re.search(r'Znale≈∫li≈õmy\s+(\d+)\s+og≈Çosze', response.text, re.I)
            
            if not ads_match:
                return None
            
            ads_count = int(ads_match.group(1))
            
            # WyciƒÖgnij nazwƒô (opcjonalnie, szybki regex)
            name_match = re.search(r'<h1[^>]*>([^<]+)</h1>', response.text)
            name = name_match.group(1).strip() if name_match else "Unknown"
            
            return {
                'user_id': user_id,
                'name': name,
                'ads_count': ads_count,
                'profile_url': profile_url,
            }
            
        except Exception as e:
            return None
    
    def scrape_listing_page(self, category, city, page=1):
        """Scrapuj jednƒÖ stronƒô listingu"""
        
        # Losuj miasto lub kategoriƒô
        if random.random() > 0.5:
            url = f"https://www.olx.pl/{category}/{city}/"
        else:
            url = f"https://www.olx.pl/{category}/"
        
        if page > 1:
            url += f"?page={page}"
        
        try:
            response = self.session.get(url, timeout=10)
            
            if response.status_code != 200:
                return []
            
            # Regex dla link√≥w do og≈Çosze≈Ñ (szybsze ni≈º BeautifulSoup)
            ad_urls = re.findall(r'href="(/d/oferta/[^"]+)"', response.text)
            
            return [f"https://www.olx.pl{url}" for url in ad_urls[:40]]  # Max 40 per stronƒô
            
        except Exception as e:
            return []
    
    def extract_user_from_ad(self, ad_url):
        """Wejd≈∫ w og≈Çoszenie i wyciƒÖgnij user_id"""
        try:
            response = self.session.get(ad_url, timeout=8)
            
            if response.status_code != 200:
                return None
            
            # Regex dla linku do profilu (szybsze)
            user_match = re.search(r'href="[^"]*?/uzytkownik/([^/"]+)', response.text)
            
            if user_match:
                return user_match.group(1)
            
            return None
            
        except Exception as e:
            return None
    
    def save_checkpoint(self):
        """Zapisz checkpoint"""
        filename = "overnight_checkpoint.csv"
        
        # Sortuj po liczbie og≈Çosze≈Ñ
        sorted_businesses = sorted(
            self.found_businesses.items(),
            key=lambda x: x[1]['ads_count'],
            reverse=True
        )
        
        with open(filename, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Ranking', 'User_ID', 'Nazwa', 'Liczba_Ogloszen', 'URL_Profilu'])
            
            for rank, (user_id, data) in enumerate(sorted_businesses, 1):
                writer.writerow([
                    rank,
                    user_id,
                    data['name'],
                    data['ads_count'],
                    data['profile_url']
                ])
        
        # Cache checked_users ≈ºeby nie sprawdzaƒá ponownie
        cache_file = "overnight_checkpoint_cache.json"
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump({
                'checked_users': list(self.checked_users),
                'last_update': datetime.now().isoformat(),
            }, f, indent=2)
        
        # JSON ze statystykami
        stats_file = filename.replace('.csv', '_stats.json')
        runtime = (datetime.now() - self.stats['start_time']).total_seconds()
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump({
                'ads_checked': self.stats['ads_checked'],
                'users_checked': self.stats['users_checked'],
                'businesses_found': self.stats['businesses_found'],
                'start_time': self.stats['start_time'].isoformat(),
                'runtime_seconds': runtime,
                'runtime_hours': runtime / 3600,
                'users_per_hour': self.stats['users_checked'] / (runtime / 3600) if runtime > 0 else 0,
                'total_businesses_found': len(self.found_businesses),
                'total_checked_users': len(self.checked_users),
            }, f, indent=2)
        
        return filename
    
    def print_ranking(self):
        """Wy≈õwietl aktualny ranking"""
        sorted_businesses = sorted(
            self.found_businesses.items(),
            key=lambda x: x[1]['ads_count'],
            reverse=True
        )
        
        print("\n" + "="*80)
        print(f"üèÜ AKTUALNY RANKING - TOP {min(20, len(sorted_businesses))}")
        print("="*80)
        
        for rank, (user_id, data) in enumerate(sorted_businesses[:20], 1):
            print(f"{rank:2d}. {data['name'][:30]:30s} | {data['ads_count']:5d} og≈Ç. | {user_id}")
        
        print("="*80)
    
    def print_stats(self):
        """Wy≈õwietl statystyki"""
        runtime = (datetime.now() - self.stats['start_time']).total_seconds()
        
        print(f"\nüìä STATYSTYKI:")
        print(f"   Czas dzia≈Çania: {runtime/3600:.1f}h ({runtime/60:.0f} min)")
        print(f"   Og≈Çosze≈Ñ sprawdzonych: {self.stats['ads_checked']}")
        print(f"   U≈ºytkownik√≥w sprawdzonych: {self.stats['users_checked']}")
        print(f"   Unikalnych u≈ºytkownik√≥w: {len(self.checked_users)}")
        print(f"   Firm z >300 og≈Ç: {len(self.found_businesses)}")
        
        if runtime > 0:
            print(f"   Tempo: {self.stats['users_checked']/(runtime/3600):.0f} users/h")
    
    def run_overnight(self, max_hours=8):
        """G≈Ç√≥wna pƒôtla - dzia≈Ça przez noc"""
        print("="*80)
        print("üåô OVERNIGHT SCRAPER - Start!")
        print("="*80)
        print(f"Cel: Znajd≈∫ u≈ºytkownik√≥w z >300 og≈Çosze≈Ñ")
        print(f"Max czas: {max_hours} godzin")
        print(f"Miasta: {', '.join(self.cities)}")
        print(f"Kategorie: {', '.join(self.categories)}")
        print(f"\nStart: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80 + "\n")
        
        start_time = time.time()
        max_runtime = max_hours * 3600
        
        checkpoint_counter = 0
        # Wczytaj poprzednie wyniki
        self.load_checkpoint()
        
        
        try:
            while True:
                # Sprawd≈∫ czas
                if time.time() - start_time > max_runtime:
                    print("\n‚è∞ OsiƒÖgniƒôto max czas dzia≈Çania")
                    break
                
                # Losuj kategoriƒô i miasto
                category = random.choice(self.categories)
                city = random.choice(self.cities)
                page = random.randint(1, 5)  # Pierwsze 5 stron
                
                print(f"\n[{datetime.now().strftime('%H:%M:%S')}] üìç {category}/{city} (strona {page})")
                
                # Pobierz listƒô og≈Çosze≈Ñ
                ad_urls = self.scrape_listing_page(category, city, page)
                
                if not ad_urls:
                    print(f"   ‚ö†Ô∏è Brak og≈Çosze≈Ñ")
                    time.sleep(2)
                    continue
                
                print(f"   Znaleziono {len(ad_urls)} og≈Çosze≈Ñ")
                
                # Sprawd≈∫ ka≈ºde og≈Çoszenie
                for i, ad_url in enumerate(ad_urls, 1):
                    self.stats['ads_checked'] += 1
                    
                    # WyciƒÖgnij user_id z og≈Çoszenia
                    user_id = self.extract_user_from_ad(ad_url)
                    
                    if not user_id:
                        continue
                    
                    if user_id in self.checked_users:
                        continue  # Ju≈º sprawdzony
                    
                    # Sprawd≈∫ profil u≈ºytkownika
                    print(f"   [{i}/{len(ad_urls)}] üë§ {user_id}...", end=" ", flush=True)
                    
                    user_data = self.get_user_ads_count_fast(user_id)
                    self.stats['users_checked'] += 1
                    checkpoint_counter += 1
                    
                    if not user_data:
                        print("‚úó")
                    else:
                        ads_count = user_data['ads_count']
                        
                        # Je≈õli >300 og≈Çosze≈Ñ ‚Üí zapisz!
                        if ads_count >= 300:
                            self.found_businesses[user_id] = user_data
                            self.stats['businesses_found'] += 1
                            print(f"üéØ {ads_count} og≈Ç. ‚Üí ZAPISANO!")
                        
                        elif ads_count >= 100:
                            print(f"‚úì {ads_count} og≈Ç.")
                        else:
                            print(f"‚óã {ads_count} og≈Ç.")
                    
                    # Co 10 u≈ºytkownik√≥w ‚Üí checkpoint i ranking
                    if checkpoint_counter % 10 == 0:
                        filename = self.save_checkpoint()
                        print(f"\nüíæ Checkpoint: {filename}")
                        self.print_ranking()
                        self.print_stats()
                    
                    # Mini delay
                    time.sleep(0.2)
                
                # Pauza miƒôdzy stronami
                time.sleep(1)
                
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è Przerwano przez u≈ºytkownika (Ctrl+C)")
        
        # Finalne zapisanie
        print("\n" + "="*80)
        print("üèÅ KONIEC SCRAPINGU")
        print("="*80)
        
        filename = self.save_checkpoint()
        print(f"\nüíæ Zapisano wyniki: {filename}")
        
        self.print_ranking()
        self.print_stats()
        
        print(f"\n‚úÖ Zako≈Ñczono: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)


if __name__ == "__main__":
    scraper = OvernightScraper()
    
    print("\nüåô OVERNIGHT SCRAPER")
    print("=" * 80)
    print("Ten skrypt bƒôdzie dzia≈Ça≈Ç przez noc szukajƒÖc firm z >300 og≈Çosze≈Ñ")
    print("\nParametry:")
    print("  - Cel: >300 og≈Çosze≈Ñ")
    print("  - Miasta: 10 najwiƒôkszych w Polsce")
    print("  - Kategorie: 8 (bez motoryzacji)")
    print("  - Checkpoint co 10 znalezionych firm")
    print("  - Ranking aktualizowany na bie≈ºƒÖco")
    print("\nMo≈ºesz przerwaƒá w ka≈ºdej chwili (Ctrl+C) - progress zostanie zapisany")
    print("=" * 80)
    
    # Zapytaj o max czas
    try:
        hours = input("\nIle godzin ma dzia≈Çaƒá? (domy≈õlnie 8): ").strip()
        max_hours = float(hours) if hours else 8
    except:
        max_hours = 8
    
    print(f"\n‚ñ∂Ô∏è START - bƒôdzie dzia≈Çaƒá przez {max_hours}h")
    print("Naci≈õnij Ctrl+C aby przerwaƒá w dowolnym momencie\n")
    
    time.sleep(2)
    
    # Uruchom
    scraper.run_overnight(max_hours=max_hours)
